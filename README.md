# NBA_2021_playoff_prop_predictions
predicting how many points an NBA player will score in a game

With the NBA playoffs set to begin on 5-18-21, I decided to develop an algorithm to predict how many points a player will score in a game.  I like to place prop bets on 'monkey knife fight,' which is a betting website for prop bets (i.e. betting on player stats).  I decided to take advantage of my improved machine learning skillset to develop an algorithm to make effective predictions.

In the accompanying Jupyter Notebook, NBA predictions.ipynb, I applied web scraping to basketballreference.com to collect stats on every player and team in every game during the 2021 season (nearly 21,000 rows of data). I used all of this data to generate a pandas data frame on stats in the following categories:
1) the team's stats averaged over the last week,
2) the opponent's stats averaged over the last week,
3) the team's stats averaged over the season up until the game of interest,
4) the opponent's stats averaged over the season up until the game of interest,
5) the player's stats averaged over the last week,
6) the player's stats averaged over the season up until the game of interest.

I eliminated rows of data where players played fewer than 25 minutes since I am only interested in making predictions on players that play most of the game.  I also eliminated rows of data where the player was coming off an injury or playing right after the all-star break.

Using the cleaned data set (113 features in total), I applied a regression analysis using ridge, lasso, support vector, and random forest regression.  The random forest performed the best and the support vector regressor performed the worst.  I combined ridge, lasso, and random forest models into a voting regressor.  The voting regressor performed better (according to R2 score).  As a result, I chose the voting regressor as the final model for predictions in the playoffs.

Using the random forest regressor, I analyzed the feature importances to determine which features are more predictive of points scored.  Player averages over the season were the most relevant in general.  USG%, which is a measure of the players useage rate, averaged over the season was the most important feature.  The player's USG% averaged over the week before the game was also important.  Predictably, field goals, field goal attempts, and points scored over the season were also highly relevant for predictions.  Opponent data does not seem important (however, see the next paragraph).  I hypothesized that opponents with better defensive statistics would play a role in predictions, but it appear to be minor.  Overall, the prediction is based on a mixture of offensive statistics averaged over both a week and the season.

In addition, the optimal lasso regression model had 24 features with non-zero weights.  There was a lot of overlap between these features and the top features from the random forest regression model.  However, one difference is the presence of numerous opponent stats, suggesting that a player's stats will vary against opponents with different styles and skill.  Note that I tested models with this reduced feature set (not shown) and did not see a meaningful effect on accuracy so it is not included in the notebook.  However, it is good to note that these 24 features resulted in similar accuracy as the 113 features.  To reduce computational complexity and improve interpretability, it would be better to use the reduced feature set in the final model.

One thing my model does not account for is the identity of the player.  The model considers their statistics but does not look for trends for each player since that would require a massive number of features via one-hot-encoding all players.  To compensate for this, I looked at the possibility of combining the prediction of the model (rather than all ~100 features) with a one-hot-encoding of all players into a second model using linear regression.  This would allow the algorithm to look for linear trends among the predicitions for specific players.  However, this did not lead to an improvement in the model, so it was not considered for final model selection.

I could not find datasets on over/under lines for how many points individual players would score each game, so it is difficult to assess the accuracy of my model.  However, I will look at the over/under lines at monkeyknifefight.com every day throughout the playoffs to collect data over time to compare to my model prediction.

For example, if the over/under for Lebron James is scoring 26 points, and my model predicts 29 points, I would choose the 'over.'  I will bet fake money on the prop bets in which my model is most confident (i.e. largest discrepancies between over/under line and model prediction) to determine the accuracy of my model.  To determine how much to bet, I will get the approximately normal distribution of the difference between actual scores and predicted scores on my test data.  I will measure the area under the distribution up to the point where monkey knife fight has set the over/under line to determine the probability of successfully winning the bet.  Since you have to correctly predict a pair of over/unders, I will multiply the probability of correct predictions for each over/under to get the probability of winning the whole bet.  With a payout of 3.6x, I need to be correct 27.8% of the time to break even.  To be safe, I will only bet when the probability of winning is greater than 0.33 and bet more money as the probability increases according to the formula 800*p^4 where p is the proability of winning the bet.

I have attached the results as of 5/31/2021, which can be seen in the attached notebook and the csv file called playoff_prop_bets. The visualizations and statistics at the end of the notebook show that my model predictions do not differ significantly from the O/U lines set by Monkey Knife Fight.  The model is correct on approximately half of the predictions.  However, because the model wagers more money on bets where it has greater confidence, I have won significantly more money than random guessing.  Starting with $1000, I am now at almost $1600, whereas the 95% of random guesses is at only $1200. 

A major flaw in the model is that the data is all based on regular season stats.  However, it is certainly likely that players behave differently in the playoffs due to greater pressure and the fact that you play the same team repeatedly in a series.  Therefore, my model may not perform as well on playoff predictions compared to the regular season predictions.

Overall, the purpose of this fun project is to showcase my skills in web scraping, data cleaning, model development, and model assessment.
